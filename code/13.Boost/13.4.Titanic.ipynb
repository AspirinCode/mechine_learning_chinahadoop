{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    acc_rate = 100 * float(acc.sum()) / a.size\n",
    "    print ('%s正确率：%.3f%%' % (tip, acc_rate))\n",
    "    return acc_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, is_train):\n",
    "    data = pd.read_csv(file_name)  # 数据文件路径\n",
    "    pd.set_option('display.width', 200)\n",
    "    print ('data.describe() = \\n', data.describe())\n",
    "    # 性别\n",
    "    # data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "    data['Sex'] = pd.Categorical(data['Sex']).codes\n",
    "\n",
    "    # 补齐船票价格缺失值\n",
    "    if len(data.Fare[data.Fare == 0]) > 0:\n",
    "        fare = np.zeros(3)\n",
    "        for f in range(0, 3):\n",
    "            fare[f] = data[data['Pclass'] == f + 1]['Fare'].dropna().median()\n",
    "        print (fare)\n",
    "        for f in range(0, 3):  # loop 0 to 2\n",
    "            data.loc[(data.Fare == 0) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n",
    "\n",
    "    print ('data.describe() = \\n', data.describe())\n",
    "    # 年龄：使用均值代替缺失值\n",
    "    # mean_age = data['Age'].dropna().mean()\n",
    "    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "    if is_train:\n",
    "        # 年龄：使用随机森林预测年龄缺失值\n",
    "        print ('随机森林预测缺失年龄：--start--')\n",
    "        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]   # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        print (age_exist)\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=20)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print ('随机森林预测缺失年龄：--over--')\n",
    "    else:\n",
    "        print ('随机森林预测缺失年龄2：--start--')\n",
    "        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]  # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print age_exist\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print age_hat\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat\n",
    "        print ('随机森林预测缺失年龄2：--over--')\n",
    "    data['Age'] = pd.cut(data['Age'], bins=6, labels=np.arange(6))\n",
    "\n",
    "    # 起始城市\n",
    "    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # 保留缺失出发城市\n",
    "    embarked_data = pd.get_dummies(data.Embarked)\n",
    "    print ('embarked_data = ', embarked_data)\n",
    "    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "    data = pd.concat([data, embarked_data], axis=1)\n",
    "\n",
    "    print (data.describe())\n",
    "    data.to_csv('New_Data.csv')\n",
    "\n",
    "    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    # x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    y = None\n",
    "    if 'Survived' in data:\n",
    "        y = data['Survived']\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 思考：这样做，其实发生了什么？\n",
    "    x = np.tile(x, (5, 1))\n",
    "    y = np.tile(y, (5, ))\n",
    "    if is_train:\n",
    "        return x, y\n",
    "    return x, data['PassengerId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_result(c, c_type):\n",
    "    file_name = 'Titanic.test.csv'\n",
    "    x, passenger_id = load_data(file_name, False)\n",
    "\n",
    "    if type == 3:\n",
    "        x = xgb.DMatrix(x)\n",
    "    y = c.predict(x)\n",
    "    y[y > 0.5] = 1\n",
    "    y[~(y > 0.5)] = 0\n",
    "\n",
    "    predictions_file = open(\"Prediction_%d.csv\" % c_type, \"wb\")\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "    open_file_object.writerows(zip(passenger_id, y))\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.describe() = \n",
      "        PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "[ 60.2875  14.25     8.05  ]\n",
      "data.describe() = \n",
      "        PassengerId    Survived      Pclass         Sex         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.699118    0.523008    0.381594   32.674620\n",
      "std     257.353842    0.486592    0.836071    0.477990   14.526497    1.102743    0.806057   49.608084\n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000    0.000000    0.000000    4.012500\n",
      "25%     223.500000    0.000000    2.000000    0.000000   20.125000    0.000000    0.000000    7.925000\n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000    0.000000    0.000000   14.500000\n",
      "75%     668.500000    1.000000    3.000000    1.000000   38.000000    1.000000    0.000000   31.275000\n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000    8.000000    6.000000  512.329200\n",
      "随机森林预测缺失年龄：--start--\n",
      "      Age  Survived      Fare  Parch  SibSp  Pclass\n",
      "0    22.0         0    7.2500      0      1       3\n",
      "1    38.0         1   71.2833      0      1       1\n",
      "2    26.0         1    7.9250      0      0       3\n",
      "3    35.0         1   53.1000      0      1       1\n",
      "4    35.0         0    8.0500      0      0       3\n",
      "6    54.0         0   51.8625      0      0       1\n",
      "7     2.0         0   21.0750      1      3       3\n",
      "8    27.0         1   11.1333      2      0       3\n",
      "9    14.0         1   30.0708      0      1       2\n",
      "10    4.0         1   16.7000      1      1       3\n",
      "11   58.0         1   26.5500      0      0       1\n",
      "12   20.0         0    8.0500      0      0       3\n",
      "13   39.0         0   31.2750      5      1       3\n",
      "14   14.0         0    7.8542      0      0       3\n",
      "15   55.0         1   16.0000      0      0       2\n",
      "16    2.0         0   29.1250      1      4       3\n",
      "18   31.0         0   18.0000      0      1       3\n",
      "20   35.0         0   26.0000      0      0       2\n",
      "21   34.0         1   13.0000      0      0       2\n",
      "22   15.0         1    8.0292      0      0       3\n",
      "23   28.0         1   35.5000      0      0       1\n",
      "24    8.0         0   21.0750      1      3       3\n",
      "25   38.0         1   31.3875      5      1       3\n",
      "27   19.0         0  263.0000      2      3       1\n",
      "30   40.0         0   27.7208      0      0       1\n",
      "33   66.0         0   10.5000      0      0       2\n",
      "34   28.0         0   82.1708      0      1       1\n",
      "35   42.0         0   52.0000      0      1       1\n",
      "37   21.0         0    8.0500      0      0       3\n",
      "38   18.0         0   18.0000      0      2       3\n",
      "..    ...       ...       ...    ...    ...     ...\n",
      "856  45.0         1  164.8667      1      1       1\n",
      "857  51.0         1   26.5500      0      0       1\n",
      "858  24.0         1   19.2583      3      0       3\n",
      "860  41.0         0   14.1083      0      2       3\n",
      "861  21.0         0   11.5000      0      1       2\n",
      "862  48.0         1   25.9292      0      0       1\n",
      "864  24.0         0   13.0000      0      0       2\n",
      "865  42.0         1   13.0000      0      0       2\n",
      "866  27.0         1   13.8583      0      1       2\n",
      "867  31.0         0   50.4958      0      0       1\n",
      "869   4.0         1   11.1333      1      1       3\n",
      "870  26.0         0    7.8958      0      0       3\n",
      "871  47.0         1   52.5542      1      1       1\n",
      "872  33.0         0    5.0000      0      0       1\n",
      "873  47.0         0    9.0000      0      0       3\n",
      "874  28.0         1   24.0000      0      1       2\n",
      "875  15.0         1    7.2250      0      0       3\n",
      "876  20.0         0    9.8458      0      0       3\n",
      "877  19.0         0    7.8958      0      0       3\n",
      "879  56.0         1   83.1583      1      0       1\n",
      "880  25.0         1   26.0000      1      0       2\n",
      "881  33.0         0    7.8958      0      0       3\n",
      "882  22.0         0   10.5167      0      0       3\n",
      "883  28.0         0   10.5000      0      0       2\n",
      "884  25.0         0    7.0500      0      0       3\n",
      "885  39.0         0   29.1250      5      0       3\n",
      "886  27.0         0   13.0000      0      0       2\n",
      "887  19.0         1   30.0000      0      0       1\n",
      "889  26.0         1   30.0000      0      0       1\n",
      "890  32.0         0    7.7500      0      0       3\n",
      "\n",
      "[714 rows x 6 columns]\n",
      "随机森林预测缺失年龄：--over--\n",
      "embarked_data =       C  Q  S  U\n",
      "0    0  0  1  0\n",
      "1    1  0  0  0\n",
      "2    0  0  1  0\n",
      "3    0  0  1  0\n",
      "4    0  0  1  0\n",
      "5    0  1  0  0\n",
      "6    0  0  1  0\n",
      "7    0  0  1  0\n",
      "8    0  0  1  0\n",
      "9    1  0  0  0\n",
      "10   0  0  1  0\n",
      "11   0  0  1  0\n",
      "12   0  0  1  0\n",
      "13   0  0  1  0\n",
      "14   0  0  1  0\n",
      "15   0  0  1  0\n",
      "16   0  1  0  0\n",
      "17   0  0  1  0\n",
      "18   0  0  1  0\n",
      "19   1  0  0  0\n",
      "20   0  0  1  0\n",
      "21   0  0  1  0\n",
      "22   0  1  0  0\n",
      "23   0  0  1  0\n",
      "24   0  0  1  0\n",
      "25   0  0  1  0\n",
      "26   1  0  0  0\n",
      "27   0  0  1  0\n",
      "28   0  1  0  0\n",
      "29   0  0  1  0\n",
      "..  .. .. .. ..\n",
      "861  0  0  1  0\n",
      "862  0  0  1  0\n",
      "863  0  0  1  0\n",
      "864  0  0  1  0\n",
      "865  0  0  1  0\n",
      "866  1  0  0  0\n",
      "867  0  0  1  0\n",
      "868  0  0  1  0\n",
      "869  0  0  1  0\n",
      "870  0  0  1  0\n",
      "871  0  0  1  0\n",
      "872  0  0  1  0\n",
      "873  0  0  1  0\n",
      "874  1  0  0  0\n",
      "875  1  0  0  0\n",
      "876  0  0  1  0\n",
      "877  0  0  1  0\n",
      "878  0  0  1  0\n",
      "879  1  0  0  0\n",
      "880  0  0  1  0\n",
      "881  0  0  1  0\n",
      "882  0  0  1  0\n",
      "883  0  0  1  0\n",
      "884  0  0  1  0\n",
      "885  0  1  0  0\n",
      "886  0  0  1  0\n",
      "887  0  0  1  0\n",
      "888  0  0  1  0\n",
      "889  1  0  0  0\n",
      "890  0  1  0  0\n",
      "\n",
      "[891 rows x 4 columns]\n",
      "       PassengerId    Survived      Pclass         Sex       SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  Embarked_U\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642    0.647587    0.523008    0.381594   32.674620    0.188552    0.086420    0.722783    0.002245\n",
      "std     257.353842    0.486592    0.836071    0.477990    1.102743    0.806057   49.608084    0.391372    0.281141    0.447876    0.047351\n",
      "min       1.000000    0.000000    1.000000    0.000000    0.000000    0.000000    4.012500    0.000000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000    0.000000    0.000000    0.000000    7.925000    0.000000    0.000000    0.000000    0.000000\n",
      "50%     446.000000    0.000000    3.000000    1.000000    0.000000    0.000000   14.500000    0.000000    0.000000    1.000000    0.000000\n",
      "75%     668.500000    1.000000    3.000000    1.000000    1.000000    0.000000   31.275000    0.000000    0.000000    1.000000    0.000000\n",
      "max     891.000000    1.000000    3.000000    1.000000    8.000000    6.000000  512.329200    1.000000    1.000000    1.000000    1.000000\n",
      "x =  [[3 1 1 ..., 0 0 1]\n",
      " [1 0 2 ..., 1 0 0]\n",
      " [3 0 1 ..., 0 0 1]\n",
      " ..., \n",
      " [3 0 1 ..., 0 0 1]\n",
      " [1 1 1 ..., 1 0 0]\n",
      " [3 1 2 ..., 0 1 0]]\n",
      "[0]\teval-error:0.150808\ttrain-error:0.129303\n",
      "[1]\teval-error:0.121185\ttrain-error:0.104759\n",
      "[2]\teval-error:0.121185\ttrain-error:0.100269\n",
      "[3]\teval-error:0.100539\ttrain-error:0.080216\n",
      "[4]\teval-error:0.104129\ttrain-error:0.077522\n",
      "[5]\teval-error:0.098743\ttrain-error:0.076324\n",
      "[6]\teval-error:0.087971\ttrain-error:0.070937\n",
      "[7]\teval-error:0.087074\ttrain-error:0.066746\n",
      "[8]\teval-error:0.084381\ttrain-error:0.066148\n",
      "[9]\teval-error:0.081688\ttrain-error:0.065549\n",
      "[10]\teval-error:0.081688\ttrain-error:0.064053\n",
      "[11]\teval-error:0.08079\ttrain-error:0.062855\n",
      "[12]\teval-error:0.074506\ttrain-error:0.058964\n",
      "[13]\teval-error:0.072711\ttrain-error:0.059563\n",
      "[14]\teval-error:0.070018\ttrain-error:0.055971\n",
      "[15]\teval-error:0.070018\ttrain-error:0.055971\n",
      "[16]\teval-error:0.070018\ttrain-error:0.054475\n",
      "[17]\teval-error:0.071813\ttrain-error:0.055373\n",
      "[18]\teval-error:0.070018\ttrain-error:0.054475\n",
      "[19]\teval-error:0.071813\ttrain-error:0.055373\n",
      "Logistic回归：80.700%\n",
      "随机森林：93.716%\n",
      "XGBoost：92.819%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x, y = load_data('Titanic.train.csv', True)\n",
    "    print ('x = ', x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "    #\n",
    "    lr = LogisticRegression(penalty='l2')\n",
    "    lr.fit(x_train, y_train)\n",
    "    y_hat = lr.predict(x_test)\n",
    "    lr_acc = accuracy_score(y_test, y_hat)\n",
    "    # write_result(lr, 1)\n",
    "\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    y_hat = rfc.predict(x_test)\n",
    "    rfc_acc = accuracy_score(y_test, y_hat)\n",
    "    # write_result(rfc, 2)\n",
    "\n",
    "    # XGBoost\n",
    "    data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "    watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "    param = {'max_depth': 6, 'eta': 0.8, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "             # 'subsample': 1, 'alpha': 0, 'lambda': 0, 'min_child_weight': 1}\n",
    "    bst = xgb.train(param, data_train, num_boost_round=20, evals=watch_list)\n",
    "    y_hat = bst.predict(data_test)\n",
    "    # write_result(bst, 3)\n",
    "    y_hat[y_hat > 0.5] = 1\n",
    "    y_hat[~(y_hat > 0.5)] = 0\n",
    "    xgb_acc = accuracy_score(y_test, y_hat)\n",
    "\n",
    "    print ('Logistic回归：%.3f%%' % (100*lr_acc))\n",
    "    print ('随机森林：%.3f%%' % (100*rfc_acc))\n",
    "    print ('XGBoost：%.3f%%' % (100*xgb_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
